---
title: "Data Science HW3"
author: "Sabah Usmani"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```


```{r load_libraries}
library(tidyverse)
library(readxl)
library(patchwork)
```
### Problem 2
Loading the accelerometer data 

```{r}
accel_data <- read_csv("data/accel_data.csv")

```
Clean and tidy accelerometer data 

```{r}
clean_accel <- accel_data %>%
  janitor::clean_names() %>%
  pivot_longer(activity_1:activity_1440,
               names_to = "minute",
               names_prefix = "activity_",
               values_to = "count", 
               ) %>%
  mutate(day = tolower(day)) %>%
  mutate(day_type = if_else(day == "saturday"|day == "sunday" , "weekend", "weekday")) %>%
  mutate(minute = as.numeric(minute)) #turn activity into a numeric 

#nrow(clean_accel)
#ncol(clean_accel)

```
This clean accelerometer dataset has 6 variables and 50,400 observations. The variables in this dataset are week, day_id for the day of the week (day_id), the day of the week (day), minute (includes 1440 mins of the 24 hour day), the activity count for each minute of the 24-hour day (count) and a weekday weekend variable (day_type). 

Aggregating across minutes to create a total activity for each day 

```{r}
summary_table <- clean_accel %>% 
  group_by(week, day_id, day) %>%
  summarize(sum_count = sum(count))

#Assessing trends using simple plot 
summary_table %>%
  ggplot() +
  geom_point(aes(x = day_id, y = sum_count, color = day)) +
  labs(title = "Relationship day and total aggregate activity count per day ", x = "day", y = "activity count")
  theme_bw()

```
From the summary table and scatter plot above, we do not see any clear trend between day and total aggregate activity count, even when seperated by days of the week. While the plot was not required for second part of Q2, I thought it was important in order to access any trends in the aggregated table. 

Single panel plot that shows the 24-hour activity time courses for each day

```{r}
clean_accel %>%
  ggplot() +
  geom_point(aes(x = minute, y = count, color = day), alpha = 0.4) +
  labs(title = "24 hour activity time course by days", x = "minute of the day", y = "activity count per minute")
  theme_bw()

```
The plot above shows that there is no visual correlation between the day of the week and the activity count per minute. The activity count generally falls between 0 to 2500 during the course of the day with many outliers. It is lower in the earlier part of the day and then gradually rises. 

### Problem 3
Loading the data 

```{r}
library(p8105.datasets)
data("ny_noaa") 

str(ny_noaa)

```

These data were accessed from the NOAA National Climatic Data Center. It is publicaly accessible weather data. The data contain the following variables weather station id (id), date of observation (date), precipitation in tenth of mm (prcp), snowfall in mm (snow), snow depth in mm (snwd), maximum temperature in degrees C (tmax) and minimum temperature in degrees C (tmin). There is a lot of missing data in this dataset (i.e. NA values in the table) which can bias our analysis  if the reason for this is nonrandom. There are missing data for all the variables except id and date. 

cleaning the data, correcting the class and creating a separate variable for day, month, year.

```{r}
clean_noaa <- ny_noaa %>% 
  mutate(tmax = as.numeric(tmax)) %>% 
  mutate(tmin = as.numeric(tmin)) %>%
   separate(date, into = c("year", "month", "day")) %>%
  mutate(year = as.numeric(year), month = as.numeric(month), day = as.numeric(day), prcp = as.numeric(prcp), snow = as.numeric(snow), snwd = as.numeric(snwd))
  
#clean_noaa %>%
  #pull(snow) 


```
The most common observed value for snowfall is zero. This is because there are many days where there is no snow fall in NY.

Two panel plot showing average max temperature in january and july in each station across years 

```{r}
plot_data <- clean_noaa %>%
  group_by(id, year, month) %>%
    filter(month == 1 | month == 7) %>%
  summarize(mean_tmax = mean(tmax))
  
  
#ggplot 
plot_data %>%  
  mutate(month = if_else(month == 1, "Januray", "July")) %>%
ggplot() + 
  geom_point(aes(x = year, y = mean_tmax), alpha = 0.5) +
  facet_grid(.~month) +
    labs(title = "Average max temperature in january and july accross the years", x = "year", y = "Average max temp")
  theme_bw()

```
The average max temperature is much higher in July accross all stations than in january. There is out obvious outlier in january and a few outliers in July. 

Two-panel plot for tmax vs. tmin 

```{r}

violin_plot <- clean_noaa %>%
  ggplot(aes(y = tmax, x = tmin)) +
  geom_violin() +
  labs(title = "tmax vs. tmin ", x = "tmin", y = "tmax")

```
make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year

```{r}
library(patchwork)


snow_data <- clean_noaa %>%
  filter(snow > 0 & snow < 100) 

 snow_plot <- snow_data %>%
  mutate(year = as.character(year)) %>%
  group_by(year) %>%
ggplot() +
  geom_boxplot(aes(y= snow, x = year), width = 0.5) +
  theme_bw() +
  theme(axis.text = element_text(size = 5))    
  labs(title = "distribution of snowfall values greater than 0 and less than 100  by year")

violin_plot /snow_plot

```

Problem 1 

```{r}
library(p8105.datasets)
data("instacart")
```


```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```






